# ============================================================
# ULTRA-FAST EfficientDet Training - Optimized for Speed
# Key Improvements: Cached preprocessing, parallel loading, efficient batching
# ============================================================

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
import matplotlib.pyplot as plt
import os
import json
import cv2
import kagglehub
from glob import glob
from sklearn.model_selection import train_test_split
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor

print("âœ… TensorFlow version:", tf.__version__)

# ============================================================
# CONFIGURATION
# ============================================================
IMG_SIZE = 320  # Smaller for faster training (was 416)
BATCH_SIZE = 16  # Larger batches (was 8)
NUM_EPOCHS = 50  # Reduced (was 100)
INITIAL_LR = 1e-3
MIN_LR = 1e-7
CONFIDENCE_THRESHOLD = 0.5

# Mixed precision for 2-3x speedup
policy = tf.keras.mixed_precision.Policy('mixed_float16')
tf.keras.mixed_precision.set_global_policy(policy)
print("âœ… Mixed precision enabled")

# ============================================================
# MOUNT DRIVE
# ============================================================
from google.colab import drive
drive.mount('/content/gdrive')

SAVE_DIR = '/content/gdrive/MyDrive/EfficientDet_Trash_Detection'
os.makedirs(SAVE_DIR, exist_ok=True)

# ============================================================
# DOWNLOAD DATASET
# ============================================================
print("ðŸ“¥ Downloading TACO dataset...")
try:
    path = kagglehub.dataset_download("sohamchaudhari2004/taco-trash-detection-dataset")
except:
    path = kagglehub.dataset_download("kneroma/tacotrashdataset")
print(f"âœ… Dataset downloaded: {path}")

# ============================================================
# DATA PARSING
# ============================================================
def parse_taco_annotations(dataset_path):
    ann_files = glob(os.path.join(dataset_path, "**/*.json"), recursive=True)
    if not ann_files:
        raise ValueError("No annotation files found!")

    ann_file = ann_files[0]
    with open(ann_file, 'r') as f:
        coco_data = json.load(f)

    categories = {cat['id']: cat['name'] for cat in coco_data['categories']}
    label_map = {name: idx for idx, name in enumerate(categories.values())}
    num_classes = len(categories)

    images = {img['id']: img for img in coco_data['images']}

    image_annotations = {}
    for ann in coco_data['annotations']:
        img_id = ann['image_id']
        if img_id not in image_annotations:
            image_annotations[img_id] = []
        image_annotations[img_id].append(ann)

    data = []
    img_dir = os.path.dirname(ann_file)

    for img_id, anns in tqdm(image_annotations.items(), desc="Loading annotations"):
        if img_id not in images:
            continue

        img_info = images[img_id]
        img_filename = img_info['file_name']

        # Find image path
        possible_paths = [
            os.path.join(img_dir, img_filename),
            os.path.join(dataset_path, img_filename),
            os.path.join(dataset_path, 'data', img_filename),
        ]

        img_path = None
        for p in possible_paths:
            if os.path.exists(p):
                img_path = p
                break

        if img_path is None:
            found = glob(os.path.join(dataset_path, "**", img_filename), recursive=True)
            if found:
                img_path = found[0]
            else:
                continue

        boxes = []
        labels = []

        for ann in anns:
            if 'bbox' not in ann:
                continue

            x, y, w, h = ann['bbox']
            if w <= 0 or h <= 0:
                continue

            cat_id = ann['category_id']
            if cat_id not in categories:
                continue

            boxes.append([x, y, x + w, y + h])
            labels.append(categories[cat_id])

        if boxes:
            data.append({
                'image_path': img_path,
                'boxes': np.array(boxes, dtype=np.float32),
                'labels': labels
            })

    print(f"âœ… Loaded {len(data)} images with {num_classes} classes")
    return data, label_map, num_classes

dataset, label_map, NUM_CLASSES = parse_taco_annotations(path)
train_data, val_data = train_test_split(dataset, test_size=0.15, random_state=42)

print(f"ðŸ“Š Train: {len(train_data)} | Val: {len(val_data)}")

# Save label map
with open(f"{SAVE_DIR}/label_map.json", "w") as f:
    json.dump(label_map, f, indent=2)

# ============================================================
# FAST PREPROCESSING WITH CACHING
# ============================================================
def preprocess_single_image(item, label_map, img_size, augment=False):
    """Preprocess one image - will be cached"""
    img = cv2.imread(item['image_path'])
    if img is None:
        return None

    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    orig_h, orig_w = img.shape[:2]

    boxes = item['boxes'].copy()
    labels = item['labels']

    # Normalize boxes
    boxes[:, [0, 2]] /= orig_w
    boxes[:, [1, 3]] /= orig_h

    # Augmentation
    if augment:
        if np.random.rand() > 0.5:
            img = cv2.flip(img, 1)
            boxes[:, [0, 2]] = 1 - boxes[:, [2, 0]]

        if np.random.rand() > 0.5:
            img = np.clip(img * np.random.uniform(0.8, 1.2), 0, 255).astype(np.uint8)

    # Resize
    img = cv2.resize(img, (img_size, img_size))
    img = img.astype(np.float32) / 255.0

    # Get first box and label
    label_idx = label_map[labels[0]]
    box = boxes[0]

    # One-hot encode
    class_vector = np.zeros(NUM_CLASSES, dtype=np.float32)
    class_vector[label_idx] = 1.0

    return img, class_vector.reshape(1, -1), box.reshape(1, 4)

# ============================================================
# PRELOAD ALL DATA (CRITICAL OPTIMIZATION)
# ============================================================
def preload_dataset(data_list, label_map, img_size, augment=False):
    """Preload and cache all images in memory"""
    print(f"ðŸ”„ Preloading {len(data_list)} images (augment={augment})...")

    cached_data = []

    # Use parallel processing for loading
    with ThreadPoolExecutor(max_workers=4) as executor:
        futures = []
        for item in data_list:
            future = executor.submit(preprocess_single_image, item, label_map, img_size, augment)
            futures.append(future)

        for future in tqdm(futures, desc="Loading"):
            result = future.result()
            if result is not None:
                cached_data.append(result)

    print(f"âœ… Cached {len(cached_data)} images in memory")
    return cached_data

# Preload training data
train_cached = preload_dataset(train_data, label_map, IMG_SIZE, augment=True)
val_cached = preload_dataset(val_data, label_map, IMG_SIZE, augment=False)

# ============================================================
# ULTRA-FAST DATASET FROM MEMORY
# ============================================================
def create_fast_dataset(cached_data, batch_size, shuffle=True):
    """Create dataset from preloaded memory - MUCH faster"""

    images = np.array([item[0] for item in cached_data], dtype=np.float32)
    classes = np.array([item[1] for item in cached_data], dtype=np.float32)
    boxes = np.array([item[2] for item in cached_data], dtype=np.float32)

    classes = classes.squeeze(1)
    boxes = boxes.squeeze(1)

    dataset = tf.data.Dataset.from_tensor_slices((
        images,
        {'class_predictions': classes, 'box_predictions': boxes}
    ))

    if shuffle:
        dataset = dataset.shuffle(buffer_size=len(cached_data))

    dataset = dataset.batch(batch_size)
    dataset = dataset.prefetch(tf.data.AUTOTUNE)

    return dataset

train_dataset = create_fast_dataset(train_cached, BATCH_SIZE, shuffle=True)
val_dataset = create_fast_dataset(val_cached, BATCH_SIZE, shuffle=False)

print("âœ… Fast datasets created from memory")

# ============================================================
# SIMPLIFIED MODEL (FASTER)
# ============================================================
def create_fast_model(num_classes, img_size=320):
    """Faster, simpler model"""
    inputs = layers.Input(shape=(img_size, img_size, 3))

    # EfficientNet-B0 backbone
    backbone = tf.keras.applications.EfficientNetB0(
        include_top=False,
        weights='imagenet',
        input_tensor=inputs
    )

    # Freeze more layers for faster training
    for layer in backbone.layers[:100]:
        layer.trainable = False

    features = backbone.output

    # Simpler detection heads
    x = layers.Conv2D(128, 3, padding='same', activation='swish')(features)
    x = layers.BatchNormalization()(x)
    x = layers.Dropout(0.2)(x)

    # Class head
    class_head = layers.Conv2D(64, 3, padding='same', activation='swish')(x)
    class_head = layers.GlobalAveragePooling2D()(class_head)
    class_head = layers.Dense(num_classes, activation='sigmoid',
                              dtype='float32', name='class_predictions')(class_head)

    # Box head
    box_head = layers.Conv2D(64, 3, padding='same', activation='swish')(x)
    box_head = layers.GlobalAveragePooling2D()(box_head)
    box_head = layers.Dense(4, activation='sigmoid',
                           dtype='float32', name='box_predictions')(box_head)

    model = keras.Model(inputs=inputs, outputs=[class_head, box_head])
    return model

print("ðŸ—ï¸ Building fast model...")
model = create_fast_model(NUM_CLASSES, IMG_SIZE)

# ============================================================
# LOSS FUNCTIONS
# ============================================================
def focal_loss(y_true, y_pred, alpha=0.25, gamma=2.0):
    epsilon = 1e-7
    y_pred = tf.clip_by_value(y_pred, epsilon, 1 - epsilon)
    ce = -y_true * tf.math.log(y_pred) - (1 - y_true) * tf.math.log(1 - y_pred)
    focal = alpha * tf.pow(1 - y_pred, gamma) * ce
    return tf.reduce_mean(focal)

def smooth_l1_loss(y_true, y_pred):
    """Faster than IoU loss"""
    diff = tf.abs(y_true - y_pred)
    less_than_one = tf.cast(tf.less(diff, 1.0), tf.float32)
    loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)
    return tf.reduce_mean(loss)

# ============================================================
# COMPILE - Fixed: Use float LR for ReduceLROnPlateau compatibility
# ============================================================
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=INITIAL_LR),
    loss={
        'class_predictions': focal_loss,
        'box_predictions': smooth_l1_loss
    },
    loss_weights={'class_predictions': 1.0, 'box_predictions': 2.0},
    metrics={'class_predictions': ['accuracy']}
)

print("âœ… Model compiled")

# ============================================================
# CALLBACKS
# ============================================================
callbacks = [
    keras.callbacks.EarlyStopping(
        monitor='val_loss',
        patience=15,
        restore_best_weights=True,
        verbose=1
    ),
    keras.callbacks.ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=5,
        min_lr=MIN_LR,
        verbose=1
    ),
    keras.callbacks.ModelCheckpoint(
        f"{SAVE_DIR}/efficientdet_best.keras",
        monitor='val_loss',
        save_best_only=True,
        verbose=1
    ),
    keras.callbacks.CSVLogger(
        f"{SAVE_DIR}/training_log.csv"
    )
]

# ============================================================
# TRAIN
# ============================================================
print("\n" + "="*60)
print("ðŸš€ Starting FAST training...")
print(f"  Epochs: {NUM_EPOCHS}")
print(f"  Batch size: {BATCH_SIZE}")
print(f"  Image size: {IMG_SIZE}x{IMG_SIZE}")
print(f"  Steps per epoch: ~{len(train_cached) // BATCH_SIZE}")
print("="*60 + "\n")

history = model.fit(
    train_dataset,
    epochs=NUM_EPOCHS,
    validation_data=val_dataset,
    callbacks=callbacks,
    verbose=1
)

# ============================================================
# SAVE
# ============================================================
model.save(f"{SAVE_DIR}/efficientdet_final.keras")
print("âœ… Model saved!")

# ============================================================
# VISUALIZATION
# ============================================================
plt.figure(figsize=(15, 4))

plt.subplot(1, 3, 1)
plt.plot(history.history['loss'], label='Train', linewidth=2)
plt.plot(history.history['val_loss'], label='Val', linewidth=2)
plt.title('Total Loss', fontsize=14, fontweight='bold')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(alpha=0.3)

plt.subplot(1, 3, 2)
plt.plot(history.history['class_predictions_accuracy'], label='Train', linewidth=2)
plt.plot(history.history['val_class_predictions_accuracy'], label='Val', linewidth=2)
plt.title('Classification Accuracy', fontsize=14, fontweight='bold')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(alpha=0.3)

plt.subplot(1, 3, 3)
plt.plot(history.history['box_predictions_loss'], label='Train', linewidth=2)
plt.plot(history.history['val_box_predictions_loss'], label='Val', linewidth=2)
plt.title('Box Loss', fontsize=14, fontweight='bold')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(alpha=0.3)

plt.tight_layout()
plt.savefig(f"{SAVE_DIR}/training_curves.png", dpi=200)
plt.show()

# ============================================================
# INFERENCE FUNCTION
# ============================================================
def detect_trash(image_path, model, label_map, conf_threshold=0.5, img_size=320):
    img = cv2.imread(image_path)
    if img is None:
        return None, None, None

    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    orig_h, orig_w = img_rgb.shape[:2]

    img_resized = cv2.resize(img_rgb, (img_size, img_size))
    img_normalized = img_resized.astype(np.float32) / 255.0
    img_batch = np.expand_dims(img_normalized, axis=0)

    class_pred, box_pred = model.predict(img_batch, verbose=0)

    detected_classes = []
    detected_boxes = []
    detected_scores = []

    top_class_idx = np.argmax(class_pred[0])
    top_score = class_pred[0, top_class_idx]

    if top_score > conf_threshold:
        inv_label_map = {v: k for k, v in label_map.items()}
        class_name = inv_label_map[top_class_idx]

        box = box_pred[0]
        xmin = int(box[0] * orig_w)
        ymin = int(box[1] * orig_h)
        xmax = int(box[2] * orig_w)
        ymax = int(box[3] * orig_h)

        detected_classes.append(class_name)
        detected_boxes.append([xmin, ymin, xmax, ymax])
        detected_scores.append(float(top_score))

    return detected_boxes, detected_classes, detected_scores

print("\nâœ… TRAINING COMPLETE!")
print(f"\nðŸ’¡ Speed Improvements:")
print(f"  âœ“ Preloaded all images in memory (no disk I/O)")
print(f"  âœ“ Parallel image loading")
print(f"  âœ“ Removed inefficient generator")
print(f"  âœ“ Larger batch size (16 vs 8)")
print(f"  âœ“ Smaller image size (320 vs 416)")
print(f"  âœ“ Simplified model architecture")
print(f"  âœ“ Faster loss function (Smooth L1 vs IoU)")
print(f"\nâš¡ Expected speedup: 20-50x faster per epoch!")
